{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Create a DataFrame with mock data\n",
        "data = {\n",
        "    'transaction_id': [1, 2, 3],\n",
        "    'customer_id': [101, 102, 103],\n",
        "    'product_id': [1001, 1002, 1003],\n",
        "    'quantity': [2, 1, 5],\n",
        "    'timestamp': ['2024-10-31 10:00:00', '2024-10-31 11:00:00', '2024-10-31 12:00:00']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('sales_data.csv', index=False)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1730646199528
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('sales_data.csv')\n",
        "print(df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "   transaction_id  customer_id  product_id  quantity            timestamp\n0               1          101        1001         2  2024-10-31 10:00:00\n1               2          102        1002         1  2024-10-31 11:00:00\n2               3          103        1003         5  2024-10-31 12:00:00\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730646199873
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['sale_date'] = pd.to_datetime(df['timestamp'])\n",
        "df.drop(columns=['timestamp'], inplace=True)\n",
        "print(df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "   transaction_id  customer_id  product_id  quantity           sale_date\n0               1          101        1001         2 2024-10-31 10:00:00\n1               2          102        1002         1 2024-10-31 11:00:00\n2               3          103        1003         5 2024-10-31 12:00:00\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730646200142
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.exc import OperationalError\n",
        "import time\n",
        "\n",
        "# Create a connection to the database. Using SQLite for simplicity, an engine with a timeout & serialized mode can help manage multiple connections\n",
        "engine = create_engine('sqlite:///sales.db', connect_args={'timeout': 60, 'check_same_thread': False})  \n",
        "\n",
        "# Load the data into the 'sales' table. Retry Logic: Implement a retry mechanism to handle the database is locked error by retrying the operation after a short delay.\n",
        "retries = 5\n",
        "for attempt in range(retries):\n",
        "    try:\n",
        "        # Use a context manager to ensure the connection is closed properly\n",
        "        with engine.connect() as connection:\n",
        "            df.to_sql('sales', con=connection, if_exists='append', index=False)\n",
        "        break\n",
        "    except OperationalError as e:\n",
        "        if 'database is locked' in str(e):\n",
        "            time.sleep(5)  # Wait for 5 seconds before retrying\n",
        "        else:\n",
        "            raise"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730646526534
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Use environment variables for configuration\n",
        "db_url = os.getenv('DATABASE_URL', 'sqlite:///sales.db')\n",
        "file_path = os.getenv('FILE_PATH', 'sales_data.csv')\n",
        "\n",
        "# Create a connection to the database\n",
        "engine = create_engine(db_url, connect_args={'timeout': 60, 'check_same_thread': False})\n",
        "\n",
        "# Read and load the data\n",
        "df = pd.read_csv(file_path)\n",
        "df['sale_date'] = pd.to_datetime(df['timestamp'])\n",
        "df.drop(columns=['timestamp'], inplace=True)\n",
        "\n",
        "# Retry logic to handle database is locked error\n",
        "retries = 5\n",
        "for attempt in range(retries):\n",
        "    try:\n",
        "        # Use a context manager to ensure the connection is closed properly\n",
        "        with engine.connect() as connection:\n",
        "            df.to_sql('sales', con=connection, if_exists='append', index=False)\n",
        "        break\n",
        "    except OperationalError as e:\n",
        "        if 'database is locked' in str(e):\n",
        "            time.sleep(5)  # Wait for 5 seconds before retrying\n",
        "        else:\n",
        "            raise\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730646852194
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Use environment variables for configuration\n",
        "db_url = os.getenv('DATABASE_URL', 'sqlite:///sales.db')\n",
        "file_path = os.getenv('FILE_PATH', 'sales_data.csv')\n",
        "\n",
        "# Create a connection to the database with a timeout\n",
        "engine = create_engine(db_url, connect_args={'timeout': 60, 'check_same_thread': False})\n",
        "\n",
        "# Retry logic to handle database is locked error\n",
        "retries = 5\n",
        "for attempt in range(retries):\n",
        "    try:\n",
        "        logging.info(\"ETL process started\")\n",
        "        \n",
        "        # Read and load the data\n",
        "        df = pd.read_csv(file_path)\n",
        "        df['sale_date'] = pd.to_datetime(df['timestamp'])\n",
        "        df.drop(columns=['timestamp'], inplace=True)\n",
        "        \n",
        "        # Use a context manager to ensure the connection is closed properly\n",
        "        with engine.connect() as connection:\n",
        "            df.to_sql('sales', con=connection, if_exists='append', index=False)\n",
        "        \n",
        "        logging.info(\"ETL process completed successfully\")\n",
        "        break\n",
        "    except OperationalError as e:\n",
        "        if 'database is locked' in str(e):\n",
        "            logging.warning(f\"Database is locked, retrying... ({attempt + 1}/{retries})\")\n",
        "            time.sleep(5)  # Wait for 5 seconds before retrying\n",
        "        else:\n",
        "            logging.error(f\"OperationalError occurred: {e}\")\n",
        "            raise\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Unexpected error occurred: {e}\")\n",
        "        raise"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "INFO:root:ETL process started\nWARNING:root:Database is locked, retrying... (1/5)\nINFO:root:ETL process started\nWARNING:root:Database is locked, retrying... (2/5)\nINFO:root:ETL process started\nWARNING:root:Database is locked, retrying... (3/5)\nINFO:root:ETL process started\nWARNING:root:Database is locked, retrying... (4/5)\nINFO:root:ETL process started\nWARNING:root:Database is locked, retrying... (5/5)\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730647587455
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cryptography.fernet import Fernet\n",
        "\n",
        "# Generate a key for encryption\n",
        "key = Fernet.generate_key()\n",
        "cipher_suite = Fernet(key)\n",
        "\n",
        "# Encrypt customer IDs\n",
        "df['customer_id'] = df['customer_id'].apply(lambda x: cipher_suite.encrypt(str(x).encode()).decode())"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730647607934
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for new columns and handle them\n",
        "expected_columns = {'transaction_id', 'customer_id', 'product_id', 'quantity', 'sale_date'}\n",
        "new_columns = set(df.columns) - expected_columns\n",
        "\n",
        "if new_columns:\n",
        "    logging.warning(f\"New columns detected: {new_columns}\")\n",
        "    # Handle new columns appropriately"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730647742954
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "es"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}